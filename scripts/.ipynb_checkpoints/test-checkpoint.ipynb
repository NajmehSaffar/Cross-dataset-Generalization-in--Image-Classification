{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from dataset import load_data\n",
    "from Baseline1.tester import Tester as Tester1\n",
    "from Baseline2.tester import Tester as Tester2\n",
    "from SupCon.tester import Tester as Tester3\n",
    "from utils import *\n",
    "#from pyDeLong import delong_roc_variance\n",
    "#from compare_auc_delong_xu import *\n",
    "import torch\n",
    "\n",
    "# Create a class to simulate command-line arguments\n",
    "class ArgumentParser(argparse.ArgumentParser):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ArgumentParser, self).__init__(*args, **kwargs)\n",
    "        self.args = None\n",
    "\n",
    "    def parse_args(self, args=None, namespace=None):\n",
    "        if self.args is None:\n",
    "            return super(ArgumentParser, self).parse_args(args=args, namespace=namespace)\n",
    "        else:\n",
    "            return self.parse_known_args(self.args, namespace)\n",
    "        \n",
    "\n",
    "def parse_arguments_from_list(args_list):\n",
    "    parser = ArgumentParser(description='PyTorch Model Training')\n",
    "    parser.add_argument('--data_dir', type=str, default='../data/', help='Path to the data directory')\n",
    "    return parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/yandexdataschool/roc_comparison\n",
    "# AUC comparison adapted from https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=float)\n",
    "    # +1 is due to Python using 0-based indexing instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=float)\n",
    "    ty = np.empty([k, n], dtype=float)\n",
    "    tz = np.empty([k, m + n], dtype=float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    pvalue = 2 * (1 - scipy.stats.norm.cdf(z, 0, 1))\n",
    "    return z, np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    return order, label_1_count\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    return calc_pvalue(aucs, delongcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading the data ...\n",
      "\n",
      "Set1 nfiles: 6000 ,  Set2 nfiles: 3140 ,  Set3 nfiles: 3804\n",
      "\n",
      "done ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "The p-value of [[-29.21482022]] is between Baseline1 and SupCon (Test Set = D1a).\n",
      "The p-value of [[-52.13225215]] is between Baseline2 and SupCon (Test Set = D1a).\n",
      "The p-value of [[-30.95712695]] is between Baseline1 and SupCon (Test Set = D1b).\n",
      "The p-value of [[-51.6125446]] is between Baseline2 and SupCon (Test Set = D1b).\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "The p-value of [[-1.73024239]] is between Baseline1 and SupCon (Test Set = D2a).\n",
      "The p-value of [[-1.16300532]] is between Baseline2 and SupCon (Test Set = D2a).\n",
      "The p-value of [[-0.24429802]] is between Baseline1 and SupCon (Test Set = D2b).\n",
      "The p-value of [[-1.16412486]] is between Baseline2 and SupCon (Test Set = D2b).\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "The p-value of [[-3.7470398]] is between Baseline1 and SupCon (Test Set = D3a).\n",
      "The p-value of [[-3.41316363]] is between Baseline2 and SupCon (Test Set = D3a).\n",
      "The p-value of [[-1.00391578]] is between Baseline1 and SupCon (Test Set = D3b).\n",
      "The p-value of [[-0.96836075]] is between Baseline2 and SupCon (Test Set = D3b).\n",
      "\n",
      "0 day(s) 0 hour(s) 8 minute(s) 8 second(s)\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    \n",
    "    # Load the dataframe from a file and return the loaded dataframe\n",
    "    [df1_trn, df1_vld, df1_a, df1_b], [df2_trn, df2_vld, df2_a, df2_b], [df3_trn, df3_vld, df3_a, df3_b] = load_data(args)\n",
    "    \n",
    "    backup = \"/backup02\"\n",
    "    \n",
    "    tester1_D2D3 = Tester1(df1_b, df1_a, args.data_dir, backup, setup = \"Baseline1\", exp = \"D2D3\") # Instantiate the tester \n",
    "    tester2_D2D3 = Tester2(df1_b, df1_a, args.data_dir, backup, setup = \"Baseline2\", exp = \"D2D3\") # Instantiate the tester \n",
    "    tester3_D2D3 = Tester3(df1_b, df1_a, args.data_dir, backup, setup = \"SupCon\", exp = \"D2D3\") # Instantiate the tester \n",
    "    lbllist1, outlist1, predlist1 = tester1_D2D3.test(tester1_D2D3.ldr_tsta)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D2D3.test(tester2_D2D3.ldr_tsta)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D2D3.test(tester3_D2D3.ldr_tsta)\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D1a).')\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D1a).')\n",
    "    \n",
    "    lbllist1, outlist1, predlist1 = tester1_D2D3.test(tester1_D2D3.ldr_tstb)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D2D3.test(tester2_D2D3.ldr_tstb)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D2D3.test(tester3_D2D3.ldr_tstb)\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D1b).')\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D1b).')\n",
    "    \n",
    "    #for i in range(len(lbllist1)) :\n",
    "    #    print(lbllist1[i], \" \", lbllist2[i], \" \", lbllist3[i])\n",
    "    \n",
    "    tester1_D1D3 = Tester1(df1_b, df1_a, args.data_dir, backup, setup = \"Baseline1\", exp = \"D1D3\") # Instantiate the tester \n",
    "    tester2_D1D3 = Tester2(df1_b, df1_a, args.data_dir, backup, setup = \"Baseline2\", exp = \"D1D3\") # Instantiate the tester \n",
    "    tester3_D1D3 = Tester3(df1_b, df1_a, args.data_dir, backup, setup = \"SupCon\", exp = \"D1D3\") # Instantiate the tester \n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D3.test(tester1_D1D3.ldr_tsta)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D3.test(tester2_D1D3.ldr_tsta)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D3.test(tester3_D1D3.ldr_tsta)\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D2a).')\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D2a).')\n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D3.test(tester1_D1D3.ldr_tstb)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D3.test(tester2_D1D3.ldr_tstb)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D3.test(tester3_D1D3.ldr_tstb)\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D2b).')\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D2b).')\n",
    "    \n",
    "    \n",
    "    tester1_D1D2 = Tester1(df1_b, df1_a, args.data_dir, backup, setup = \"Baseline1\", exp = \"D1D2\") # Instantiate the tester \n",
    "    tester2_D1D2 = Tester2(df1_b, df1_a, args.data_dir, backup, setup = \"Baseline2\", exp = \"D1D2\") # Instantiate the tester \n",
    "    tester3_D1D2 = Tester3(df1_b, df1_a, args.data_dir, backup, setup = \"SupCon\", exp = \"D1D2\") # Instantiate the tester \n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D2.test(tester1_D1D2.ldr_tsta)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D2.test(tester2_D1D2.ldr_tsta)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D2.test(tester3_D1D2.ldr_tsta)\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D3a).')\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D3a).')\n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D2.test(tester1_D1D2.ldr_tstb)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D2.test(tester2_D1D2.ldr_tstb)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D2.test(tester3_D1D2.ldr_tstb)\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D3b).')\n",
    "    z, p_value = delong_roc_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D3b).')\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Define your desired argument values\n",
    "    args_list = ['--data_dir', '../data/']\n",
    "    \n",
    "    args = parse_arguments_from_list(args_list)\n",
    "    \n",
    "    start = time.time()\n",
    "    main(args)\n",
    "    end = time.time()\n",
    "    days, hours, minutes, seconds = getTime(end-start)\n",
    "    print(f\"\\n{int(days)} day(s) {int(hours)} hour(s) {int(minutes)} minute(s) {int(seconds)} second(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading the data ...\n",
      "\n",
      "Set1 nfiles: 6000 ,  Set2 nfiles: 3140 ,  Set3 nfiles: 3804\n",
      "\n",
      "done ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "The p-value of 0.9390213328968655 is between Baseline1 and SupCon (Test Set = D1a).\n",
      "The p-value of 0.7401724286359563 is between Baseline2 and SupCon (Test Set = D1a).\n",
      "The p-value of 0.9405679594159173 is between Baseline1 and SupCon (Test Set = D1b).\n",
      "The p-value of 0.7365170938916059 is between Baseline2 and SupCon (Test Set = D1b).\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "The p-value of 0.9195823127288063 is between Baseline1 and SupCon (Test Set = D2a).\n",
      "The p-value of 0.5876662225043936 is between Baseline2 and SupCon (Test Set = D2a).\n",
      "The p-value of 0.9319718000559429 is between Baseline1 and SupCon (Test Set = D2b).\n",
      "The p-value of 0.5860705537889579 is between Baseline2 and SupCon (Test Set = D2b).\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "The p-value of 0.8390706181037322 is between Baseline1 and SupCon (Test Set = D3a).\n",
      "The p-value of 0.9954613212158487 is between Baseline2 and SupCon (Test Set = D3a).\n",
      "The p-value of 0.848692191986353 is between Baseline1 and SupCon (Test Set = D3b).\n",
      "The p-value of 0.9998113924953498 is between Baseline2 and SupCon (Test Set = D3b).\n",
      "\n",
      "0 day(s) 0 hour(s) 8 minute(s) 10 second(s)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "def delong_test(y_true, y_pred_model1, y_pred_model2):\n",
    "    \"\"\"\n",
    "    Perform DeLong test to compare the AUCs of two models.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array-like): True labels (0 or 1).\n",
    "        y_pred_model1 (array-like): Predicted probabilities by model 1.\n",
    "        y_pred_model2 (array-like): Predicted probabilities by model 2.\n",
    "        \n",
    "    Returns:\n",
    "        float: Test statistic (z-score).\n",
    "        float: Two-sided p-value.\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    y1 = y_pred_model1\n",
    "    y2 = y_pred_model2\n",
    "    # Calculate the differences (d) between the predicted probabilities of the two models\n",
    "    d = y1 - y2\n",
    "    # Compute the mean difference (c) of the d values\n",
    "    # The mean difference provides an estimate of the average discrepancy between the models.\n",
    "    c = np.mean(d)\n",
    "    # Calculate the variance of the differences (var)\n",
    "    # The variance measures the spread or variability of the differences between the models. \n",
    "    var = np.var(d, ddof=1) # (np.mean(d**2) - np.mean(d)**2) / n\n",
    "    # Calculate the covariance to quantify the relationship between the predicted probabilities of the two models.\n",
    "    cov_y1_y2 = np.cov(y1, y2, rowvar=False, ddof=1)[0, 1]\n",
    "    cov_y1_y_true = np.cov(y1, y_true, rowvar=False, ddof=1)[0, 1]\n",
    "    cov_y2_y_true = np.cov(y2, y_true, rowvar=False, ddof=1)[0, 1]\n",
    "    \n",
    "    cov = cov_y1_y2 - cov_y1_y_true * cov_y2_y_true / np.var(y_true, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic (z)\n",
    "    # The test statistic measures the number of standard deviations the mean difference is away from zero.\n",
    "    z = c / np.sqrt(var)\n",
    "    \n",
    "    # Compute the p-value using the cumulative distribution function (CDF) of the standard normal distribution\n",
    "    p_value = 2 * (1 - norm.cdf(np.abs(z)))\n",
    "    \n",
    "    return z, p_value\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    # Load the dataframe from a file and return the loaded dataframe\n",
    "    [df1_trn, df1_vld, df1_a, df1_b], [df2_trn, df2_vld, df2_a, df2_b], [df3_trn, df3_vld, df3_a, df3_b] = load_data(args)\n",
    "    \n",
    "    tester1_D2D3 = Tester1(df1_b, df1_a, args.data_dir, setup = \"Baseline1\", exp = \"D2D3\") # Instantiate the tester \n",
    "    tester2_D2D3 = Tester2(df1_b, df1_a, args.data_dir, setup = \"Baseline2\", exp = \"D2D3\") # Instantiate the tester \n",
    "    tester3_D2D3 = Tester3(df1_b, df1_a, args.data_dir, setup = \"SupCon\", exp = \"D2D3\") # Instantiate the tester \n",
    "    lbllist1, outlist1, predlist1 = tester1_D2D3.test(tester1_D2D3.ldr_tsta)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D2D3.test(tester2_D2D3.ldr_tsta)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D2D3.test(tester3_D2D3.ldr_tsta)\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D1a).')\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D1a).')\n",
    "    \n",
    "    lbllist1, outlist1, predlist1 = tester1_D2D3.test(tester1_D2D3.ldr_tstb)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D2D3.test(tester2_D2D3.ldr_tstb)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D2D3.test(tester3_D2D3.ldr_tstb)\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D1b).')\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D1b).')\n",
    "    \n",
    "    #for i in range(len(lbllist1)) :\n",
    "    #    print(lbllist1[i], \" \", lbllist2[i], \" \", lbllist3[i])\n",
    "    \n",
    "    tester1_D1D3 = Tester1(df1_b, df1_a, args.data_dir, setup = \"Baseline1\", exp = \"D1D3\") # Instantiate the tester \n",
    "    tester2_D1D3 = Tester2(df1_b, df1_a, args.data_dir, setup = \"Baseline2\", exp = \"D1D3\") # Instantiate the tester \n",
    "    tester3_D1D3 = Tester3(df1_b, df1_a, args.data_dir, setup = \"SupCon\", exp = \"D1D3\") # Instantiate the tester \n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D3.test(tester1_D1D3.ldr_tsta)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D3.test(tester2_D1D3.ldr_tsta)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D3.test(tester3_D1D3.ldr_tsta)\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D2a).')\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D2a).')\n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D3.test(tester1_D1D3.ldr_tstb)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D3.test(tester2_D1D3.ldr_tstb)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D3.test(tester3_D1D3.ldr_tstb)\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D2b).')\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D2b).')\n",
    "    \n",
    "    \n",
    "    tester1_D1D2 = Tester1(df1_b, df1_a, args.data_dir, setup = \"Baseline1\", exp = \"D1D2\") # Instantiate the tester \n",
    "    tester2_D1D2 = Tester2(df1_b, df1_a, args.data_dir, setup = \"Baseline2\", exp = \"D1D2\") # Instantiate the tester \n",
    "    tester3_D1D2 = Tester3(df1_b, df1_a, args.data_dir, setup = \"SupCon\", exp = \"D1D2\") # Instantiate the tester \n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D2.test(tester1_D1D2.ldr_tsta)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D2.test(tester2_D1D2.ldr_tsta)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D2.test(tester3_D1D2.ldr_tsta)\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D3a).')\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D3a).')\n",
    "    lbllist1, outlist1, predlist1 = tester1_D1D2.test(tester1_D1D2.ldr_tstb)\n",
    "    lbllist2, outlist2, predlist2 = tester2_D1D2.test(tester2_D1D2.ldr_tstb)\n",
    "    lbllist3, outlist3, predlist3 = tester3_D1D2.test(tester3_D1D2.ldr_tstb)\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist1.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline1 and SupCon (Test Set = D3b).')\n",
    "    z, p_value = delong_test(lbllist1.numpy(), outlist2.numpy(), outlist3.numpy())\n",
    "    print(f'The p-value of {p_value} is between Baseline2 and SupCon (Test Set = D3b).')\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Define your desired argument values\n",
    "    args_list = ['--data_dir', '../data/']\n",
    "    \n",
    "    args = parse_arguments_from_list(args_list)\n",
    "    \n",
    "    start = time.time()\n",
    "    main(args)\n",
    "    end = time.time()\n",
    "    days, hours, minutes, seconds = getTime(end-start)\n",
    "    print(f\"\\n{int(days)} day(s) {int(hours)} hour(s) {int(minutes)} minute(s) {int(seconds)} second(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading the data ...\n",
      "\n",
      "Set1 nfiles: 6000 ,  Set2 nfiles: 3140 ,  Set3 nfiles: 3804\n",
      "\n",
      "done ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n",
      "Device:  cuda\n",
      "loading the model ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your desired argument values\n",
    "args_list = ['--data_dir', '../data/']\n",
    "args = parse_arguments_from_list(args_list)\n",
    "# Load the dataframe from a file and return the loaded dataframe\n",
    "[df1_trn, df1_vld, df1_a, df1_b], [df2_trn, df2_vld, df2_a, df2_b], [df3_trn, df3_vld, df3_a, df3_b] = load_data(args)\n",
    "\n",
    "tester1_D2D3 = Tester1(df1_b, df1_a, args.data_dir, setup = \"Baseline1\", exp = \"D2D3\") # Instantiate the tester \n",
    "tester2_D2D3 = Tester2(df1_b, df1_a, args.data_dir, setup = \"Baseline2\", exp = \"D2D3\") # Instantiate the tester \n",
    "tester3_D2D3 = Tester3(df1_b, df1_a, args.data_dir, setup = \"SupCon\", exp = \"D2D3\") # Instantiate the tester \n",
    "lbllist1, outlist1, predlist1 = tester1_D2D3.test(tester1_D2D3.ldr_tsta)\n",
    "lbllist2, outlist2, predlist2 = tester2_D2D3.test(tester2_D2D3.ldr_tsta)\n",
    "lbllist3, outlist3, predlist3 = tester3_D2D3.test(tester3_D2D3.ldr_tsta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 23.1852,  -3.6657,  22.4458,  ..., -14.8234, -11.8361, -12.9829])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "var() received an invalid combination of arguments - got (ddof=int, dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (tuple of ints dim, bool unbiased, bool keepdim)\n * (tuple of ints dim, *, int correction, bool keepdim)\n      didn't match because some of the keywords were incorrect: ddof, dtype, out, axis\n * (bool unbiased)\n * (tuple of names dim, bool unbiased, bool keepdim)\n * (tuple of names dim, *, int correction, bool keepdim)\n      didn't match because some of the keywords were incorrect: ddof, dtype, out, axis\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3742671/3402431234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Calculate the variance of the differences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mvar_diff_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Calculate the AUC covariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3719\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "\u001b[0;31mTypeError\u001b[0m: var() received an invalid combination of arguments - got (ddof=int, dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (tuple of ints dim, bool unbiased, bool keepdim)\n * (tuple of ints dim, *, int correction, bool keepdim)\n      didn't match because some of the keywords were incorrect: ddof, dtype, out, axis\n * (bool unbiased)\n * (tuple of names dim, bool unbiased, bool keepdim)\n * (tuple of names dim, *, int correction, bool keepdim)\n      didn't match because some of the keywords were incorrect: ddof, dtype, out, axis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Step 1: Obtain predicted probabilities for each model\n",
    "model1_probs = outlist1# predicted probabilities for model 1\n",
    "model2_probs = outlist3# predicted probabilities for model 2\n",
    "\n",
    "# Step 2: Extract true labels\n",
    "true_labels = lbllist1# true labels from test dataset\n",
    "\n",
    "# Step 3: Compute AUCs\n",
    "auc_model1 = roc_auc_score(true_labels, model1_probs)\n",
    "auc_model2 = roc_auc_score(true_labels, model2_probs)\n",
    "\n",
    "# Step 4: Perform DeLong test\n",
    "# Calculate the differences in predicted probabilities\n",
    "diff_probs = model1_probs - model2_probs\n",
    "\n",
    "# Calculate the variance of the differences\n",
    "var_diff_probs = np.var(diff_probs)\n",
    "\n",
    "# Calculate the AUC covariance\n",
    "cov_auc = np.cov(true_labels, diff_probs)[0, 1]\n",
    "\n",
    "# Calculate the Z-score\n",
    "z_score = cov_auc / np.sqrt(var_diff_probs)\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 2 * (1 - norm.cdf(np.abs(z_score)))\n",
    "\n",
    "# Print the AUCs and p-value\n",
    "print(\"AUC Model 1:\", auc_model1)\n",
    "print(\"AUC Model 2:\", auc_model2)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
